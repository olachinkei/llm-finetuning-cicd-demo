wandb_version: 1

lora_config:
  desc: null
  value:
    r: 8
    lora_alpha: 32
    target_modules:
    - q_proj
    - v_proj
    lora_dropout: 0.05
    bias: none
    task_type: CAUSAL_LM
training:
  desc: null
  value:
    evaluation_strategy: steps
    per_device_train_batch_size: 2
    gradient_accumulation_steps: 2
    report_to: wandb
    warmup_steps: 5
    max_steps: 100
    learning_rate: 0.0002
    fp16: true
    logging_steps: 5
    save_steps: 25
    output_dir: outputs
dataset_version:
  desc: null
  value: downsampled
MODEL_NAME:
  desc: null
  value: Finetuned-Review-Autocompletion
BASE_MODEL:
  desc: null
  value: facebook/opt-125m
_wandb:
  desc: null
  value:
    code_path: code/fine_tuning.py
    python_version: 3.10.12
    cli_version: 0.15.8
    framework: huggingface
    huggingface_version: 4.32.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1693281369.195693
    t:
      1:
      - 1
      - 11
      - 49
      - 51
      - 55
      - 71
      - 98
      2:
      - 1
      - 11
      - 49
      - 51
      - 55
      - 71
      - 98
      3:
      - 2
      - 16
      - 23
      4: 3.10.12
      5: 0.15.8
      6: 4.32.0
      8:
      - 5
