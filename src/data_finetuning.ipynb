{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6cbc9a-be45-4c05-a135-5271c03f8f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import wandb\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3e39f5-d44d-41d3-8097-8a8ca5abdd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_ENTITY\"] = \"reviewco\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Autocompletion with evaluation\"\n",
    "os.environ[\"WANDB_USERNAME\"] = \"keisuke-kamata\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"gradients\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8f0fcb-822c-469e-bc73-470d951829bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lora_config\": {\n",
    "        \"r\": 16,\n",
    "        \"lora_alpha\": 32,\n",
    "        \"target_modules\": [\"q_proj\", \"v_proj\"],\n",
    "        \"lora_dropout\": .05,\n",
    "        \"bias\": \"none\",\n",
    "        \"task_type\": \"CAUSAL_LM\"\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"evaluation_strategy\": \"steps\",\n",
    "        \"per_device_train_batch_size\": 4,\n",
    "        \"gradient_accumulation_steps\": 4,\n",
    "        \"report_to\": \"wandb\",\n",
    "        \"warmup_steps\": 5,\n",
    "        \"max_steps\": 50,\n",
    "        \"learning_rate\": 2e-4,\n",
    "        \"fp16\": True,\n",
    "        \"logging_steps\": 5,\n",
    "        \"save_steps\": 25,\n",
    "        \"output_dir\": 'outputs'\n",
    "    },\n",
    "    \"dataset_version\": \"downsampled\"\n",
    "}\n",
    "MODEL_NAME = \"Finetuned-Review-Autocompletion\"\n",
    "BASE_MODEL = \"facebook/opt-125m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6941531-9d19-4ab0-89e6-1bcfeb976d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    #load_in_8bit=True,\n",
    "    device_map='auto',\n",
    ")\n",
    "data = load_dataset(\"databricks/databricks-dolly-15k\",split=\"train\")\n",
    "data_train_test = data.train_test_split(test_size=0.2)\n",
    "data_train_valid = data_train_test[\"train\"]\n",
    "data_train_valid = data_train_valid.train_test_split(test_size=0.2)\n",
    "data_train = data_train_valid[\"train\"]\n",
    "data_valid = data_train_valid[\"test\"]\n",
    "data_test = data_train_test[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da79b83-04dd-4f37-9960-0a0820849488",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkeisuke-kamata\u001b[0m (\u001b[33mreviewco\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/work/wandb/run-20230827_060512-wtkz3zzd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/runs/wtkz3zzd' target=\"_blank\">glowing-breeze-8</a></strong> to <a href='https://wandb.ai/reviewco/Autocompletion%20with%20evaluation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/reviewco/Autocompletion%20with%20evaluation' target=\"_blank\">https://wandb.ai/reviewco/Autocompletion%20with%20evaluation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/runs/wtkz3zzd' target=\"_blank\">https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/runs/wtkz3zzd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(config=config, job_type=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6b8c47-3596-4121-88b0-083e62eacb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_NO_INPUT_FORMAT = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "### Response\"\"\"\n",
    "\n",
    "PROMPT_WITH_INPUT_FORMAT = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "### Instruction:\n",
    "{instruction}\n",
    "Input:\n",
    "{context}\n",
    "### Response\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19d936b4-4cbe-4c00-8cc6-65d03711ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstructDataset(Dataset):\n",
    "    def __init__(self, json_list, tokenizer, ignore_index=-100):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.ignore_index = ignore_index\n",
    "        self.features = []\n",
    "        \n",
    "        for j in tqdm(json_list):\n",
    "            # In cases like open_qa where context information is not necessary, there is no input column.\n",
    "            # Therefore, we differentiate the template sentences based on whether the input column is present or not.\n",
    "            if 'context' in j:\n",
    "                source_text = PROMPT_WITH_INPUT_FORMAT.format_map(j)\n",
    "            else:\n",
    "                source_text = PROMPT_NO_INPUT_FORMAT.format_map(j)\n",
    "            \n",
    "            # Combine the instruction sentence and the response sentence, and insert an EOS token at the end\n",
    "            example_text = source_text + j['response'] + self.tokenizer.eos_token\n",
    "            \n",
    "            # okenize only the instruction sentence (up to 'The following is a task to ~### Response:')\n",
    "            # What we want is the length of the instruction sentence.\n",
    "            source_tokenized = self.tokenizer(\n",
    "                source_text,\n",
    "                padding='longest',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_length=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Tokenize both the instruction sentence and the response sentence\n",
    "            example_tokenized = self.tokenizer(\n",
    "                example_text, \n",
    "                padding='longest', \n",
    "                truncation=True, \n",
    "                max_length=512, \n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            input_ids = example_tokenized['input_ids'][0]\n",
    "            \n",
    "            # Copy the input sentence as is to be the correct answer that the LLM generates.\n",
    "            labels = copy.deepcopy(input_ids)\n",
    "            \n",
    "            # Length up to the instruction sentence\n",
    "            source_len = source_tokenized['length'][0]\n",
    "            \n",
    "            # Since the desired correct sentence for the LLM to generate also includes the instruction sentence,\n",
    "            # we fill the section of the instruction sentence with -100 as IGNORE_INDEX to avoid calculating the CrossEntropyLoss.\n",
    "            labels[:source_len] = self.ignore_index\n",
    "            \n",
    "            self.features.append({\n",
    "                'input_ids': input_ids,\n",
    "                'labels': labels\n",
    "            })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "        \n",
    "class InstructCollator():\n",
    "    def __init__(self, tokenizer, ignore_index=-100):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.ignore_index = -100\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        input_batch = []\n",
    "        label_batch = []\n",
    "        for example in examples:\n",
    "            input_batch.append(example['input_ids'])\n",
    "            label_batch.append(example['labels'])\n",
    "        \n",
    "        input_ids = pad_sequence(\n",
    "            input_batch, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "        # labelsのpaddingトークンは先程と同様にignore_indexである-100で埋める\n",
    "        labels = pad_sequence(\n",
    "            label_batch, batch_first=True, padding_value=self.ignore_index\n",
    "        )\n",
    "\n",
    "        # attention_maskはbool値でもいいらしい\n",
    "        attention_mask = input_ids.ne(self.tokenizer.pad_token_id)\n",
    "            \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'attention_mask': attention_mask\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f223825-15e9-4c0b-84d0-b5c8bbd8d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9606/9606 [00:05<00:00, 1745.28it/s]\n",
      "100%|██████████| 2402/2402 [00:01<00:00, 1560.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 01:14, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.896800</td>\n",
       "      <td>2.836390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.670900</td>\n",
       "      <td>2.735138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.605000</td>\n",
       "      <td>2.705029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.516900</td>\n",
       "      <td>2.691258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.634500</td>\n",
       "      <td>2.671077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.825600</td>\n",
       "      <td>2.657326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>2.730300</td>\n",
       "      <td>2.647658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>2.640867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>2.722800</td>\n",
       "      <td>2.636999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.638600</td>\n",
       "      <td>2.635682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs/checkpoint-25)... Done. 0.1s\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./outputs/checkpoint-50)... Done. 0.0s\n"
     ]
    }
   ],
   "source": [
    "# Setup for LoRa\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "model.lm_head = CastOutputToFloat(model.lm_head)\n",
    "\n",
    "lora_config = LoraConfig(**wandb.config[\"lora_config\"])\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=InstructDataset(data_train, tokenizer),\n",
    "    eval_dataset=InstructDataset(data_valid, tokenizer),\n",
    "    args=transformers.TrainingArguments(**wandb.config[\"training\"]),\n",
    "    data_collator=InstructCollator(tokenizer)\n",
    ")\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n",
    "model.save_pretrained(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09ee9d0c-b723-46e5-a8a4-b5f27c93204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./output)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Artifact finetuned-model>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft = wandb.Artifact(f\"finetuned-model\", type=\"model\")\n",
    "model_ft.add_dir(\"output\")\n",
    "run.log_artifact(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959664d1-cd9f-4c95-87b7-974b7d0a19d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▃▂▂▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▇▇█▇█▇█</td></tr><tr><td>eval/samples_per_second</td><td>███▂▂▁▂▁▂▁</td></tr><tr><td>eval/steps_per_second</td><td>███▂▃▁▂▁▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▂▂▃▃▄▄▅▅▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇███</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▄▃▁▃▇▅▄▅▃</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>2.63568</td></tr><tr><td>eval/runtime</td><td>6.6331</td></tr><tr><td>eval/samples_per_second</td><td>362.121</td></tr><tr><td>eval/steps_per_second</td><td>45.378</td></tr><tr><td>train/epoch</td><td>0.08</td></tr><tr><td>train/global_step</td><td>50</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>2.6386</td></tr><tr><td>train/total_flos</td><td>135231330263040.0</td></tr><tr><td>train/train_loss</td><td>2.69113</td></tr><tr><td>train/train_runtime</td><td>74.3827</td></tr><tr><td>train/train_samples_per_second</td><td>10.755</td></tr><tr><td>train/train_steps_per_second</td><td>0.672</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glowing-breeze-8</strong> at: <a href='https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/runs/wtkz3zzd' target=\"_blank\">https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/runs/wtkz3zzd</a><br/> View job at <a href='https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkzMDc1NTM4/version_details/v4' target=\"_blank\">https://wandb.ai/reviewco/Autocompletion%20with%20evaluation/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjkzMDc1NTM4/version_details/v4</a><br/>Synced 5 W&B file(s), 0 media file(s), 29 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230827_060512-wtkz3zzd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b835ec-b35f-4392-ab50-acd97bc72d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
